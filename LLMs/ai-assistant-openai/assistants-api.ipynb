{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35e77e94-a5ee-4e86-bc1d-d4f652d04953",
   "metadata": {},
   "source": [
    "# OpenAI Assistants API (Beta) - YouTube Comment Responder\n",
    "\n",
    "Code authored by: Shaw Talebi <br>\n",
    "Video link: https://youtu.be/4RAvJt3fWoI <br>\n",
    "Article link: https://medium.com/towards-data-science/how-to-build-an-ai-assistant-with-openai-python-8b3b5a636f69?sk=af65504536ca6b977a4a993ecd2e80e8 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770a1d4f-8d1f-4b95-a5e6-4ab8d4ae5e17",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0441db10-1aa1-4877-949e-166636bf145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from sk import my_sk \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae0f70-7224-44f7-b0ff-39ea3e6498c0",
   "metadata": {},
   "source": [
    "### create client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2050a44a-ebca-4dd7-8214-2377b3b5db85",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=my_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e33ed25-abfa-41c6-9c50-31b9bc03c3b5",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28fb6f0-08e8-4f10-b6fc-1650186ea7eb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_for_assistant(thread, run):\n",
    "    \"\"\"\n",
    "        Function to periodically check run status of AI assistant and print run time\n",
    "    \"\"\"\n",
    "\n",
    "    # wait for assistant process prompt\n",
    "    t0 = time.time()\n",
    "    while run.status != 'completed':\n",
    "\n",
    "        # retreive status of run (this might take a few seconds or more)\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "          thread_id=thread.id,\n",
    "          run_id=run.id\n",
    "        )\n",
    "\n",
    "        # wait 0.5 seconds\n",
    "        time.sleep(0.25)\n",
    "    dt = time.time() - t0\n",
    "    print(\"Elapsed time: \" + str(dt) + \" seconds\")\n",
    "    \n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285aadc1-fcd6-4961-8d19-cbd88bc87115",
   "metadata": {},
   "source": [
    "## Vanilla Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e094a2-7f03-4372-b921-9258a6bfe909",
   "metadata": {},
   "source": [
    "### create assistant\n",
    "List of available models: https://platform.openai.com/docs/models/continuous-model-upgrades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54006d29-301a-4f99-ab2a-598c614e8c2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_AZmuCEEmRPwvoMe7Si4TuaHl', created_at=1706635876, description='Data scientist GPT for YouTube comments', file_ids=[], instructions=\"ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. It reacts to feedback aptly and concludes with its signature '–ShawGPT'. ShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\", metadata={}, model='gpt-4-0125-preview', name='ShawGPT', object='assistant', tools=[])\n"
     ]
    }
   ],
   "source": [
    "intstructions_string = \"ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. \\\n",
    "It reacts to feedback aptly and concludes with its signature '–ShawGPT'. \\\n",
    "ShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\"\n",
    "\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"ShawGPT\",\n",
    "    description=\"Data scientist GPT for YouTube comments\",\n",
    "    instructions=intstructions_string,\n",
    "    model=\"gpt-4-0125-preview\"\n",
    ")\n",
    "print(assistant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47a56d80-28be-41b5-bf53-5374503fb8c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create thread (i.e. object that handles conversations between user and assistant)\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# generate user message\n",
    "user_message = \"Great content, thank you!\"\n",
    "\n",
    "# add a user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_message\n",
    ")\n",
    "\n",
    "# send message to assistant to generate a response\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "426f9e3e-03c1-4997-9620-b64a6ea31df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.301553964614868 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'run_0EBiI28fbm4KCrcsytv5oT6l',\n",
       " 'assistant_id': 'asst_AZmuCEEmRPwvoMe7Si4TuaHl',\n",
       " 'cancelled_at': None,\n",
       " 'completed_at': 1706635879,\n",
       " 'created_at': 1706635876,\n",
       " 'expires_at': None,\n",
       " 'failed_at': None,\n",
       " 'file_ids': [],\n",
       " 'instructions': \"ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. It reacts to feedback aptly and concludes with its signature '–ShawGPT'. ShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, thus keeping the interaction natural and engaging.\",\n",
       " 'last_error': None,\n",
       " 'metadata': {},\n",
       " 'model': 'gpt-4-0125-preview',\n",
       " 'object': 'thread.run',\n",
       " 'required_action': None,\n",
       " 'started_at': 1706635876,\n",
       " 'status': 'completed',\n",
       " 'thread_id': 'thread_Q7cJEfrViygxI21eetQiwujj',\n",
       " 'tools': [],\n",
       " 'usage': Usage(completion_tokens=37, prompt_tokens=109, total_tokens=146)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wait for assistant process prompt\n",
    "run = wait_for_assistant(thread, run)\n",
    "\n",
    "# view run object (in Jupyter Lab)\n",
    "dict(run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b330bc4c-979e-462e-b6db-974417505980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're welcome! I'm glad you found it helpful. If you have any more questions or topics you're curious about, feel free to ask. –ShawGPT\n"
     ]
    }
   ],
   "source": [
    "# view messages added to thread\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11692aa5-ae26-41af-9d07-40869f92d454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_AZmuCEEmRPwvoMe7Si4TuaHl', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete assistant\n",
    "client.beta.assistants.delete(assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c7c346-ecfb-4ee3-bbcd-b55f30549610",
   "metadata": {},
   "source": [
    "### Few-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ea5bced-51fc-4f1c-bf15-c2016951e835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intstructions_string_few_shot = \"\"\"ShawGPT, functioning as a virtual data science consultant on YouTube, communicates in clear, accessible language, escalating to technical depth upon request. \\\n",
    "It reacts to feedback aptly and concludes with its signature '–ShawGPT'. \\\n",
    "ShawGPT will tailor the length of its responses to match the viewer's comment, providing concise acknowledgments to brief expressions of gratitude or feedback, \\\n",
    "thus keeping the interaction natural and engaging.\n",
    "\n",
    "Here are examples of ShawGPT responding to viewer comments.\n",
    "\n",
    "Viewer comment: This was a very thorough introduction to LLMs and answered many questions I had. Thank you.\n",
    "ShawGPT: Great to hear, glad it was helpful :) -ShawGPT\n",
    "\n",
    "Viewer comment: Epic, very useful for my BCI class\n",
    "ShawGPT: Thanks, glad to hear! -ShawGPT\n",
    "\n",
    "Viewer comment: Honestly the most straightforward explanation I've ever watched. Super excellent work Shaw. Thank you. It's so rare to find good communicators like you!\n",
    "ShawGPT: Thanks, glad it was clear -ShawGPT\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "000a7f65-c724-4a79-a9c1-383acc5d88f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"ShawGPT\",\n",
    "    description=\"Data scientist GPT for YouTube comments\",\n",
    "    instructions=intstructions_string_few_shot,\n",
    "    model=\"gpt-4-0125-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e951f4b2-f616-45d0-98f8-76a4d55f8cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3.219881772994995 seconds\n"
     ]
    }
   ],
   "source": [
    "# create new thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# generate technical question\n",
    "user_message = \"Great content, thank you!\"\n",
    "\n",
    "# add a user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_message\n",
    ")\n",
    "\n",
    "# send message to assistant to generate a response (this might take a few seconds or more)\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# wait for assistant process prompt\n",
    "run = wait_for_assistant(thread, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "127d5e26-8fdc-497a-8b8d-846fce0feaee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're welcome, happy to hear you found it useful! -ShawGPT\n"
     ]
    }
   ],
   "source": [
    "# print assistant response \n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370f1826-fee4-4fc6-9e30-257b81984726",
   "metadata": {},
   "source": [
    "#### technical question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8579192c-977f-4cc5-8ece-2d639dd4f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# generate technical question\n",
    "user_message = \"What is fat-tailedness?\"\n",
    "\n",
    "# add a user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_message\n",
    ")\n",
    "\n",
    "# send message to assistant to generate a response\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb1b3864-44ac-411c-8090-3d84ddb46461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 8.626380205154419 seconds\n"
     ]
    }
   ],
   "source": [
    "# wait for assistant process prompt\n",
    "run = wait_for_assistant(thread, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93cdbdad-89d1-4648-b4ac-790a84b320fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fat-tailedness refers to a property of a probability distribution in which the tails of the distribution are fatter than those of a normal (Gaussian) distribution. This means there is a higher likelihood of extreme values or outliers. In finance, this concept is crucial because it highlights the potential for rare but impactful events, such as stock market crashes, which are underestimated by models assuming a normal distribution. Understanding fat-tailed distributions helps in better assessing risks and making more informed decisions. -ShawGPT\n"
     ]
    }
   ],
   "source": [
    "# print assistant response\n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89b85d3c-a253-4224-a37f-758ddbf6da4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_jjlCn632652lRRnPrLHpWmjw', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete assistant\n",
    "client.beta.assistants.delete(assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f7856-81fb-4f26-ab01-94010d9194cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bad5ed-9217-4181-a56b-b0f5861c9d57",
   "metadata": {},
   "source": [
    "#### add docs for retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4892d7-4f5d-4d96-939f-5508a67a12cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create file (note: this will create a presisting file for your openai account, so be mindful about how many times you run this. \n",
    "# You can delete unnecessary files in the \"Files\" tab of your openai account. \n",
    "\n",
    "file = client.files.create(\n",
    "  file=open(\"articles/4 Ways to Quantify Fat Tails with Python _ by Shaw Talebi _ Towards Data Science.pdf\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c84ca3-af9d-48bb-8792-b3708ddd7648",
   "metadata": {},
   "source": [
    "#### create new assistant with access to docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "809379cf-243e-462b-8c91-ede852953e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"ShawGPT\",\n",
    "    description=\"Data scientist GPT for YouTube comments\",\n",
    "    instructions=intstructions_string_few_shot,\n",
    "    tools=[{\"type\": \"retrieval\"}],\n",
    "    file_ids=[file.id],\n",
    "    model=\"gpt-4-0125-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4067eac9-f940-46d2-895b-6da2a9b2e045",
   "metadata": {},
   "source": [
    "#### technical question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d274d21-33bc-45af-89ea-bef11af48c39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 45.23452281951904 seconds\n"
     ]
    }
   ],
   "source": [
    "# create new thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# generate technical question\n",
    "user_message = \"What is fat-tailedness?\"\n",
    "\n",
    "# add a user message to the thread\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=user_message\n",
    ")\n",
    "\n",
    "# send message to assistant to generate a response (this might take a several seconds or more)\n",
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    ")\n",
    "\n",
    "# wait for assistant process prompt\n",
    "run = wait_for_assistant(thread, run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "622b6f7a-1007-496b-8cf0-6bf966a99a83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fat-tailedness refers to the degree to which rare, high-magnitude events (outliers) significantly influence the overall behavior of a distribution, more so than in 'normal' (Gaussian) distributions. In the world of statistical distributions, fat tails indicate that extreme values are more likely to occur than what would be expected under a normal distribution. This characteristic is essential in various fields, including finance, where understanding the likelihood of extreme events (such as market crashes) is critical, and in other domains like natural disasters, insurance, and social network analysis, where understanding and predicting rare, significant events can be crucial.\n",
      "\n",
      "The concept of fat-tailedness ranges from thin-tailed (e.g., Gaussian distributions, where outliers are very rare) to very fat-tailed (e.g., Pareto 80-20 rule distributions, where a small number of causes lead to a large portion of the effects). This spectrum allows for a more nuanced understanding of data than simply categorizing it as following a Power Law distribution or not.\n",
      "\n",
      "To quantify fat-tailedness, various heuristics or rules of thumb can be applied, including:\n",
      "1. Power Law Tail Index (\\(\\alpha\\)): A smaller tail index indicates fatter tails. This is done by fitting a power law distribution to the data and estimating \\(\\alpha\\).\n",
      "2. Kurtosis: Measures the \"tailedness\" of a distribution. Higher kurtosis indicates fatter tails, implying a higher likelihood of extreme outcomes.\n",
      "3. Log-normal’s \\(\\sigma\\): The standard deviation of the log-normal distribution, where a larger \\(\\sigma\\) indicates fatter tails.\n",
      "4. Taleb’s \\(\\kappa\\): A metric proposed by Taleb that measures fat-tailedness on a scale from 0 (maximally thin-tailed) to 1 (maximally fat-tailed) based on the dispersion of sums of samples from the distribution.\n",
      "\n",
      "These methods offer different insights into the distribution's shape, allowing for a more detailed understanding of the data’s behavior, especially regarding the occurrence and impact of rare and extreme events - ShawGPT.\n"
     ]
    }
   ],
   "source": [
    "# print assistant response \n",
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")\n",
    "\n",
    "print(messages.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c473baee-729d-4cb9-9e0c-3bce0e64d9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AssistantDeleted(id='asst_UQcUxU8DF4wmFffX95qGyEpX', deleted=True, object='assistant.deleted')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete assistant\n",
    "client.beta.assistants.delete(assistant.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83fcf324-f529-48c3-b5c4-f044ee12805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileDeleted(id='file-P3pZuyabA2KKMpuLYKRndVyB', deleted=True, object='file')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete file\n",
    "client.files.delete(file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2c71f-91e5-4919-9c06-dc303ad5f544",
   "metadata": {},
   "source": [
    "### More Resources\n",
    "\n",
    "Assistants API: https://platform.openai.com/docs/assistants/overview <br>\n",
    "Assistants Doc: https://platform.openai.com/docs/api-reference/assistants <br>\n",
    "More on tools: https://platform.openai.com/docs/assistants/tools/code-interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f776bf-2361-4435-b7df-107ea0bea148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
